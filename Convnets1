import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import os
import cv2
from tqdm import tqdm

import tensorflow as tf
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten
from tensorflow.keras.layers import Conv2D, MaxPooling2D


Data = "E:/Final project/train"
Categories = ['ZOOPLANKTON', 'PHYTOPLANKTON']

for category in Categories:  # 
    path = os.path.join(Data,category)  # create path 
    for img in os.listdir(path):  # iterate over each category
        img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array
        plt.imshow(img_array, cmap='gray')  # graph it
        plt.show()  # display!

        break  # we just want one for now so break
    break  #...and one more!

IMG_SIZE = 60

new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))
plt.imshow(new_array, cmap='gray')
plt.show()

training_data = []

def create_training_data():
    for category in Categories:  

        path = os.path.join(Data,category)  
        class_num = Categories.index(category)  # get the classification  

        for img in tqdm(os.listdir(path)):  # iterate over each image per dogs and cats
            try:
                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array
                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size
                training_data.append([new_array, class_num])  # add this to our training_data
            except Exception as e:  # in the interest in keeping the output clean...
                pass
            except OSError as e:
                print("OSErrroBad img most likely", e, os.path.join(path,img))
            except Exception as e:
                print("general exception", e, os.path.join(path,img))

create_training_data()
l = len(training_data)
print(l)

data1 = "E:/Final project"

Category = ['test']

for cate in Category:  
    path1 = os.path.join(data1,cate)  # create path to dogs and cats
    for img in os.listdir(path1):  # iterate over each image 
        img_array1 = cv2.imread(os.path.join(path1,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array
        plt.imshow(img_array1, cmap='gray')  # graph it
        plt.show()  # display!

        break  # we just want one for now so break
    break  #...and one more!
    
new_array1 = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))
plt.imshow(new_array1, cmap='gray')
plt.show()

test_data = []

'''
def create_test_data():
     for cate in Category:  

        path1 = os.path.join(data1,cate)  
        #class_num = Categories.index(cate)    
  
        for img in tqdm(os.listdir(path1)):  # iterate over each image per dogs and cats
            try:
                img_array1 = cv2.imread(os.path.join(path1,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array
                new_array1 = cv2.resize(img_array1, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size
                test_data.append(new_array1)  # add this to our training_data
            except Exception as e:  # in the interest in keeping the output clean...
                pass
            except OSError as e:
                print("OSErrroBad img most likely", e, os.path.join(path,img))
            except Exception as e:
                print("general exception", e, os.path.join(path,img))

create_test_data()
len(test_data)
'''
import random

random.shuffle(training_data)

for sample in training_data[:10]:
    print(sample[1])
    

X = []
y = []



for features,label in training_data:
    X.append(features)
    y.append(label)



print(X[0].reshape(-1, IMG_SIZE, IMG_SIZE, 1))

X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)

X = X/255.0

model = Sequential()

model.add(Conv2D(256, (3, 3), input_shape=X.shape[1:]))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(256, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors

model.add(Dense(64))

model.add(Dense(1))
model.add(Activation('sigmoid'))

model.compile(loss='binary_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

model.fit(X, y, batch_size=32, epochs=3, validation_split=0.3)


